{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy's English model\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Add neuralcoref to SpaCy's pipeline\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try something more!\n",
    "# Let's scrap a longer text from website,\n",
    "# and process the coref_resolution with function.\n",
    "# process the ner part with function. (NER with spacy / NER with Gliner) 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text for coreference resolution\n",
    "text = \"\"\"John asked Mary to go out. She said she was busy. John was disappointed but understood.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Rihanna is basically master of the fashion universe right now, so we're naturally going to pay attention to what trends she is and isn't wearing whenever she steps out of the door (or black SUV). She's having quite the epic week, first presenting her Savage x Fenty lingerie runway show then hosting her annual Diamond Ball charity event last night. Rihanna was decked out in Givenchy for the big event, but upon arrival at the venue, she wore a T-shirt, diamonds (naturally), and a scarf, leather pants, and heels in fall's biggest color trend: pistachio green.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text with SpaCy\n",
    "doc = nlp(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun\n",
      "1\n",
      "3\n",
      "him\n",
      "22\n",
      "23\n",
      "Google\n",
      "11\n",
      "12\n",
      "the company\n",
      "19\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for cluster in doc._.coref_clusters:\n",
    "    for reference in cluster:\n",
    "    #each of these is a Span object in Spacy\n",
    "        print(reference)\n",
    "        #starting index of this reference in the text\n",
    "        print(reference.start) \n",
    "        #ending index of this reference in the text\n",
    "        print(reference.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreference cluster: Sebastian Thrun: [Sebastian Thrun, him]\n",
      "Coreference cluster: Google: [Google, the company]\n"
     ]
    }
   ],
   "source": [
    "# Print coreference clusters\n",
    "if doc._.has_coref:\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        print(f\"Coreference cluster: {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved document:\n",
      "When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of Google took Sebastian Thrun seriously.\n"
     ]
    }
   ],
   "source": [
    "# Print the resolved text\n",
    "resolved_doc = doc._.coref_resolved\n",
    "print(\"Resolved document:\")\n",
    "print(resolved_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun(PERSON)\n",
      "Google(ORG)\n",
      "2007(DATE)\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents : \n",
    "    print(f\"{entity.text}({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# from bs4 import BeautifulSoup\n",
    "# import spacy\n",
    "# import neuralcoref\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "# neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "# # html = urllib.request.urlopen('https://www.law.cornell.edu/supremecourt/text/418/683').read()\n",
    "\n",
    "# html = urllib.request.urlopen('https://www.nbcnews.com/business/business-news/biden-preparing-block-us-steel-sale-japanese-company-rcna169595').read()\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# text = ''.join([t for t in soup.find_all(text=True) if t.parent.name == 'p' and len(t) >= 25])\n",
    "# doc = nlp(text)\n",
    "# resolved_text = doc._.coref_resolved\n",
    "# sentences = [sent.string.strip() for sent in nlp(resolved_text).sents]\n",
    "# output = [sent for sent in sentences if 'president' in \n",
    "#           (' '.join([token.lemma_.lower() for token in nlp(sent)]))]\n",
    "# print('Fact count:', len(output))\n",
    "# for fact in range(len(output)):\n",
    "#     print(str(fact+1)+'.', output[fact])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:40<00:00,  8.02s/it]\n",
      "/Users/minjoo/opt/anaconda3/envs/hanhwa/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/minjoo/opt/anaconda3/envs/hanhwa/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# Initialize GLiNER with the base model\n",
    "# model = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\")\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_small-v2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for entity prediction\n",
    "# Most GLiNER models should work best when entity types are in lower case or title case\n",
    "labels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform entity prediction\n",
    "entities = model.predict_entities(processed_doc, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for entity prediction\n",
    "text = \"\"\"\n",
    "Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for entity prediction\n",
    "# Most GLiNER models should work best when entity types are in lower case or title case\n",
    "labels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo dos Santos Aveiro => Person\n",
      "5 February 1985 => Date\n",
      "Portugal national team => Teams\n",
      "Ballon d'Or => Award\n",
      "UEFA Men's Player of the Year Awards => Award\n",
      "European Golden Shoes => Award\n",
      "UEFA Champions Leagues => Competitions\n",
      "UEFA European Championship => Competitions\n",
      "UEFA Nations League => Competitions\n",
      "European Championship => Competitions\n"
     ]
    }
   ],
   "source": [
    "# Perform entity prediction\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for entity prediction\n",
    "text = \"\"\"\n",
    "David went to the concert. He said it was an amazing experience. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for entity prediction\n",
    "# Most GLiNER models should work best when entity types are in lower case or title case\n",
    "labels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minjoo/opt/anaconda3/envs/hanhwa/lib/python3.8/site-packages/gliner/data_processing/processor.py:269: UserWarning: Sentence of length 434 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wörl => Person\n",
      "Wörl => Person\n",
      "1934 => Date\n",
      "1942 => Date\n",
      "Wörl => Person\n",
      "Wörl => Person\n",
      "Wörl => Person\n",
      "Wörl => Person\n"
     ]
    }
   ],
   "source": [
    "# Perform entity prediction\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
